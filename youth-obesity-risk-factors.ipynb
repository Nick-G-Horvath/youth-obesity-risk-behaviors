{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "youth-obesity-risk-factors.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXo1KXAGxaP",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WANy223jyscL",
        "colab_type": "text"
      },
      "source": [
        "Obesity is a condition defined by the [World Health Organization](https://www.who.int/topics/obesity/en/) as a \"major risk factor for a number of chronic diseases, including diabetes, cardiovascular diseases and cancer\" and a leading preventable cause of death in the United States and worldwide. It is also a condition that is seen increasingly in children. The [Youth Risk Behavior Surveillance System (YRBSS)](https://www.cdc.gov/healthyyouth/data/yrbs/overview.htm) was developed in 1990 by the Centers for Disease Control and Prevention (CDC) to study obesity and other health outcomes and associated risk factors among youth in the United States. The motivation for this project is to understand the rates of youth obesity over time and across locations and populations within the United States, and how they are correlated with certain nutritional, behavioral, institutional, and environmental risk factors. Two datasets from the CDC are considered: [Nutrition, Physical Activity, and Obesity - Youth Risk Behavior Surveillance System](https://chronicdata.cdc.gov/Nutrition-Physical-Activity-and-Obesity/Nutrition-Physical-Activity-and-Obesity-Youth-Risk/vba9-s8jp) contains information on the prevalence of youth obesity and associated risk factors gathered from the YRBSS, and [Nutrition, Physical Activity, and Obesity - Policy and Environmental Data](https://data.cdc.gov/Nutrition-Physical-Activity-and-Obesity/Nutrition-Physical-Activity-and-Obesity-Policy-and/k8w5-7ju6) focuses on state policy and environmental factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvXnbbCbg0eo",
        "colab_type": "text"
      },
      "source": [
        "# Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZoGNxqnGWsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import heatmap\n",
        "from sklearn import preprocessing\n",
        "from sklearn import impute\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "import io\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfH41n8RPkax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity = pd.read_csv('./Youth_Risk_Behavior_Surveillance_System.csv')\n",
        "obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hunBgCnaxFXB",
        "colab_type": "text"
      },
      "source": [
        "At first glance we can see that this dataset contains information from survey questions conducted across various years, states, and population groups. Our first task is to clean this dataset, making it easier to understand and work with. Many columns are identical or redundant to others, so we can drop them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFfYsEDtJaO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.drop(columns=['YearEnd', 'LocationDesc', 'Datasource', 'Class',\n",
        "                      'Topic', 'Data_Value_Unit', 'Data_Value_Type',\n",
        "                      'Data_Value_Alt', 'Data_Value_Footnote_Symbol',\n",
        "                      'Data_Value_Footnote', 'Low_Confidence_Limit',\n",
        "                      'High_Confidence_Limit ', 'Total', 'Gender', 'Grade',\n",
        "                      'Race/Ethnicity', 'GeoLocation', 'ClassID', 'TopicID',\n",
        "                      'QuestionID', 'DataValueTypeID', 'LocationID',\n",
        "                      'StratificationCategory1', 'StratificationCategoryId1',\n",
        "                      'StratificationID1'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfMINzMAxcyg",
        "colab_type": "text"
      },
      "source": [
        "Let's give the remaining columns more appropriate names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEy0_Z4nKPPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.rename(columns={'YearStart':'Year',\n",
        "                        'LocationAbbr':'Location',\n",
        "                        'Stratification1':'Group',\n",
        "                        'Data_Value':'Value',\n",
        "                        'Sample_Size':'SampleSize'}, inplace=True)\n",
        "obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYr8PEHpyJ3c",
        "colab_type": "text"
      },
      "source": [
        "From this preview, the data in the **Value** and **SampleSize** columns both appear to be numeric. Let's check to make sure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-rZFhJqtcaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.Value.iloc[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze6jzDNet1LV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.SampleSize.iloc[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUyDokMXt5dE",
        "colab_type": "text"
      },
      "source": [
        "We can see that the **Value** column is truly numeric, but the **SampleSize** column contains numbers formatted as strings. Let's fix this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHd5e757uJ6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.SampleSize = obesity.SampleSize.apply(lambda x: pd.to_numeric(x.replace(',','')) if not pd.isnull(x) else x)\n",
        "obesity.SampleSize.iloc[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7vX2ny4zZnk",
        "colab_type": "text"
      },
      "source": [
        "The preview also makes it difficult to see what questions were asked in the surveys. Let's take a closer look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZeqGr5Bzhc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.Question.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hkspYiczriq",
        "colab_type": "text"
      },
      "source": [
        "The survey responses describe our metrics of interest, the percent of students in grades 9-12 who have an overweight classification and the percent of students in grades 9-12 who have obesity. They also describe the prevalence of the associated risk factors. In the next section we will be focusing just on the percents of students with an overweight classification and with obesity, collectively termed the high-BMI categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GZ0UyKphFet",
        "colab_type": "text"
      },
      "source": [
        "# Question 1: How do rates of high-BMI categories vary over time and by population?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvRN3LCmVbXy",
        "colab_type": "text"
      },
      "source": [
        "For right now, let's just consider the question of how many students are overweight or obese. Let's also focus on the nationwide data first, rather than by state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXK2PWVLPanE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_obesity = obesity[(obesity.Location == 'US') & (obesity.Question.isin([\n",
        "    'Percent of students in grades 9-12 who have obesity',\n",
        "    'Percent of students in grades 9-12 who have an overweight classification']\n",
        "    ))]\n",
        "us_obesity = us_obesity[['Year','Group','SampleSize','Question','Value']]\n",
        "us_obesity.sort_values(by=['Year','Group','Question'], inplace=True)\n",
        "us_obesity.reset_index(drop=True, inplace=True)\n",
        "us_obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GhtUYhVFJvX",
        "colab_type": "text"
      },
      "source": [
        "One problem with the data is that the definition of \"overweight\" is not precisely what we are interested in tracking. The [survey documentation](https://www.cdc.gov/healthyyouth/data/yrbs/pdf/2017/2017_yrbs_sadc_documentation.pdf) (pages 61-62) defines **obese** as: \"students who were >= 95th percentile for body mass index, based on sex- and age-specific reference data from the 2000 CDC growth charts\", but **overweight** as: \"students who were >= 85th percentile but <95th percentile for body mass index, based on sex- and age-specific reference data from the 2000 CDC growth charts\".\n",
        "\n",
        "This latter metric is not so straightforward to interpet. For example, would an increase in the percentage of overweight students be due to students with BMI previously below 85th percentile gaining weight, or those with BMI previously above 95th percentile losing weight? It would be unclear. Better would be a metric that, like obesity, captures all students above a certain BMI threshold.\n",
        "\n",
        "Therefore, let us define the metric **overweight or obese** as the percentage of students with BMI >= 85th percentile. Since the categories of overweight and obese are mutually exclusive and directly adjacent on the BMI scale, we can add those percentages to calculate our new metric. Before doing that, let's split the current data for the overweight and obese metrics into two separate columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbH-bKI3Tnlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_obesity = us_obesity.pivot_table(index=['Year', 'Group', 'SampleSize'],\n",
        "                                    columns='Question', values = 'Value')\n",
        "del us_obesity.columns.name\n",
        "us_obesity.reset_index(inplace=True)\n",
        "us_obesity.rename(columns={\n",
        "    'Percent of students in grades 9-12 who have an overweight classification':'Overweight',\n",
        "    'Percent of students in grades 9-12 who have obesity':'Obese'}, inplace=True)\n",
        "us_obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAk2Rb2vB2OZ",
        "colab_type": "text"
      },
      "source": [
        "Now we can create the **overweight or obese** column of data, and drop the **overweight** data that we're no longer interested in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6LrkdxtGmUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_obesity['OverweightOrObese'] = us_obesity.Overweight+us_obesity.Obese\n",
        "us_obesity.drop(columns=\"Overweight\", inplace=True)\n",
        "us_obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owK0SVhj0htW",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at how the percentages of students in the U.S. that were obese and overweight or obese has changed from 2001 to 2017:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA44El0kz8Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_obesity_total = us_obesity[us_obesity.Group == 'Total']\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "\n",
        "ax1.plot(us_obesity_total.Year, us_obesity_total.Obese, linestyle='-')\n",
        "ax1.scatter(us_obesity_total.Year, us_obesity_total.Obese, marker='o', linestyle='-')\n",
        "ax2.plot(us_obesity_total.Year, us_obesity_total.OverweightOrObese, linestyle='-')\n",
        "ax2.scatter(us_obesity_total.Year, us_obesity_total.OverweightOrObese, marker='o', linestyle='-')\n",
        "ax1.margins(0.1)\n",
        "ax1.set_xticks(us_obesity_total.Year.unique())\n",
        "ax1.set_ylim(0, 10*math.ceil(us_obesity_total.Obese.max()/10))\n",
        "ax1.set_title('Percent of students that are obese')\n",
        "ax2.margins(0.1)\n",
        "ax2.set_xticks(us_obesity_total.Year.unique())\n",
        "ax2.set_ylim(0, 10*math.ceil(us_obesity_total.OverweightOrObese.max()/10))\n",
        "ax2.set_title('Percent of students that are overweight or obese')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QhUUuy9aJg9",
        "colab_type": "text"
      },
      "source": [
        "While the percentages of obese and overweight or obese students has declined at some points, overall they have increased with time. Will this be true also when we consider specific populations? It won't make much sense to compare obesity rates for population subgroups of different types, e.g. 12th graders and males. So let's do a comparison for each type of grouping: grade, gender, and race/ethnicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCAHkcF4EXFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grade_grouping = ['9th', '10th', '11th', '12th']\n",
        "gender_grouping = ['Male', 'Female']\n",
        "race_ethnicity_grouping = ['Non-Hispanic White', 'Non-Hispanic Black',\n",
        "    'Hispanic', 'Asian', 'American Indian/Alaska Native',\n",
        "    'Hawaiian/Pacific Islander', '2 or more races']\n",
        "\n",
        "us_obesity_by_grade = us_obesity[us_obesity.Group.isin(grade_grouping)]\n",
        "us_obesity_by_gender = us_obesity[us_obesity.Group.isin(gender_grouping)]\n",
        "us_obesity_by_race_ethnicity = us_obesity[us_obesity.Group.isin(race_ethnicity_grouping)]\n",
        "\n",
        "grade_groups = us_obesity_by_grade.groupby('Group')\n",
        "gender_groups = us_obesity_by_gender.groupby('Group')\n",
        "race_ethnicity_groups = us_obesity_by_race_ethnicity.groupby('Group')\n",
        "\n",
        "fig, ((grade_ax1, grade_ax2),\n",
        "      (gender_ax1, gender_ax2),\n",
        "      (race_ethnicity_ax1, race_ethnicity_ax2)\n",
        "      ) = plt.subplots(3, 2, figsize=(15,15))\n",
        "\n",
        "for name, group in grade_groups:\n",
        "    grade_ax1.plot(group.Year, group.Obese, linestyle='-')\n",
        "    grade_ax1.scatter(group.Year, group.Obese, marker='o', linestyle='-',\n",
        "                      label=name)#s=group.SampleSize/250, \n",
        "    grade_ax2.plot(group.Year, group.OverweightOrObese, linestyle='-')\n",
        "    grade_ax2.scatter(group.Year, group.OverweightOrObese, marker='o', linestyle='-',\n",
        "                      label=name)#s=group.SampleSize/250, \n",
        "grade_ax1.margins(0.1)\n",
        "grade_ax1.set_xticks(us_obesity_by_grade.Year.unique())\n",
        "grade_ax1.set_ylim(0, 10*math.ceil(us_obesity_by_gender.Obese.max()/10))\n",
        "grade_ax1.legend(loc='lower right')\n",
        "grade_ax1.set_title('Percent of students that are obese')\n",
        "grade_ax2.margins(0.1)\n",
        "grade_ax2.set_xticks(us_obesity_by_grade.Year.unique())\n",
        "grade_ax2.set_ylim(0, 10*math.ceil(us_obesity_by_gender.OverweightOrObese.max()/10))\n",
        "grade_ax2.legend(loc='lower right')\n",
        "grade_ax2.set_title('Percent of students that are overweight or obese')\n",
        "\n",
        "for name, group in gender_groups:\n",
        "    gender_ax1.plot(group.Year, group.Obese, linestyle='-')\n",
        "    gender_ax1.scatter(group.Year, group.Obese, marker='o', linestyle='-',\n",
        "                       label=name)#s=group.SampleSize/250, \n",
        "    gender_ax2.plot(group.Year, group.OverweightOrObese, linestyle='-')\n",
        "    gender_ax2.scatter(group.Year, group.OverweightOrObese, marker='o', linestyle='-',\n",
        "                       label=name)#s=group.SampleSize/250, \n",
        "gender_ax1.margins(0.1)\n",
        "gender_ax1.set_xticks(us_obesity_by_gender.Year.unique())\n",
        "gender_ax1.set_ylim(0, 10*math.ceil(us_obesity_by_gender.Obese.max()/10))\n",
        "gender_ax1.legend(loc='lower right')\n",
        "gender_ax1.set_title('Percent of students that are obese')\n",
        "gender_ax2.margins(0.1)\n",
        "gender_ax2.set_xticks(us_obesity_by_gender.Year.unique())\n",
        "gender_ax2.set_ylim(0, 10*math.ceil(us_obesity_by_gender.OverweightOrObese.max()/10))\n",
        "gender_ax2.legend(loc='lower right')\n",
        "gender_ax2.set_title('Percent of students that are overweight or obese')\n",
        "\n",
        "for name, group in race_ethnicity_groups:\n",
        "    race_ethnicity_ax1.plot(group.Year, group.Obese, linestyle='-')\n",
        "    race_ethnicity_ax1.scatter(group.Year, group.Obese, marker='o', linestyle='-',\n",
        "                               label=name)#s=group.SampleSize/50, \n",
        "    race_ethnicity_ax2.plot(group.Year, group.OverweightOrObese, linestyle='-')\n",
        "    race_ethnicity_ax2.scatter(group.Year, group.OverweightOrObese, marker='o', linestyle='-',\n",
        "                               label=name)#s=group.SampleSize/50, \n",
        "race_ethnicity_ax1.margins(0.1)\n",
        "race_ethnicity_ax1.set_xticks(us_obesity_by_race_ethnicity.Year.unique())\n",
        "race_ethnicity_ax1.set_ylim(0, 10*math.ceil(us_obesity_by_race_ethnicity.Obese.max()/10))\n",
        "race_ethnicity_ax1.legend(loc='upper left',ncol=2)\n",
        "race_ethnicity_ax1.set_title('Percent of students that are obese')\n",
        "race_ethnicity_ax2.margins(0.1)\n",
        "race_ethnicity_ax2.set_xticks(us_obesity_by_race_ethnicity.Year.unique())\n",
        "race_ethnicity_ax2.set_ylim(0, 10*math.ceil(us_obesity_by_race_ethnicity.OverweightOrObese.max()/10))\n",
        "race_ethnicity_ax2.legend(loc='lower right',ncol=2)\n",
        "race_ethnicity_ax2.set_title('Percent of students that are overweight or obese')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vRqYNPX1wF5",
        "colab_type": "text"
      },
      "source": [
        "There isn't much that we can say about the grade subgroups. They all basically follow the overall trend, with some switching of places throughout the years. The breakdown by gender is much more stark: males have significantly higher percentages than females for all years. However, the female rates of high-BMI categories are catching up to the male rates. In fact, the increase in the percent of male students that are overweight or obese from 2001 to 2017 is negligible; the overall increase is almost entirely due to the female population.\n",
        "\n",
        "Looking at the race/ethnicity breakdown, some populations' rates are significantly variable over time. The rates of high-BMI categories among the American Indian/Alaska Native population are the highest in 2001 but the second-lowest in 2017; meanwhile, those of the Hawaiian/Pacific Islander population are second-lowest in 2001 but highest in 2017. The order of the rates of the other five population groups are more stable. In most years, the Non-Hispanic Black and Hispanic populations have the highest rates out of these five groups, followed by 2 or more races, Non-Hispanic White, and Asian. The rates of both of the high-BMI categories for the Asian population are the lowest every year.\n",
        "\n",
        "One thing you might notice is that the overall obesity rate peaks in 2013, yet in the race/ethnicity breakdown several populations are at or near their lowest points in that year. This is because there are simply so many more students in certain populations than others, specifically Non-Hispanic White, whose obesity rate peaked in 2013."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2LpBCnBXyS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_obesity[['Group','SampleSize']].groupby('Group').mean().loc[\n",
        "    race_ethnicity_grouping].sort_values(by='SampleSize', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS6SU5aC8ud1",
        "colab_type": "text"
      },
      "source": [
        "If we want to allude to the populations' differing effects on the overall trend, we can plot the data with varying marker size to illustrate populations' relative sample sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKSYhX0E8rj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_obesity_by_race_ethnicity = us_obesity[us_obesity.Group.isin(race_ethnicity_grouping)]\n",
        "\n",
        "race_ethnicity_groups = us_obesity_by_race_ethnicity.groupby('Group')\n",
        "\n",
        "fig, ((race_ethnicity_ax1, race_ethnicity_ax2)\n",
        "      ) = plt.subplots(1, 2, figsize=(15,5))\n",
        "\n",
        "for name, group in race_ethnicity_groups:\n",
        "    race_ethnicity_ax1.plot(group.Year, group.Obese, linestyle='-')\n",
        "    race_ethnicity_ax1.scatter(group.Year, group.Obese, marker='o', linestyle='-',\n",
        "                               s=group.SampleSize/50, label=name)\n",
        "    race_ethnicity_ax2.plot(group.Year, group.OverweightOrObese, linestyle='-')\n",
        "    race_ethnicity_ax2.scatter(group.Year, group.OverweightOrObese, marker='o', linestyle='-',\n",
        "                               s=group.SampleSize/50, label=name)\n",
        "race_ethnicity_ax1.margins(0.1)\n",
        "race_ethnicity_ax1.set_xticks(us_obesity_by_race_ethnicity.Year.unique())\n",
        "race_ethnicity_ax1.set_ylim(0, 10*math.ceil(us_obesity_by_race_ethnicity.Obese.max()/10))\n",
        "race_ethnicity_ax1.legend(loc='upper left',ncol=2)\n",
        "race_ethnicity_ax1.set_title('Percent of students that are obese')\n",
        "race_ethnicity_ax2.margins(0.1)\n",
        "race_ethnicity_ax2.set_xticks(us_obesity_by_race_ethnicity.Year.unique())\n",
        "race_ethnicity_ax2.set_ylim(0, 10*math.ceil(us_obesity_by_race_ethnicity.OverweightOrObese.max()/10))\n",
        "race_ethnicity_ax2.legend(loc='lower right',ncol=2)\n",
        "race_ethnicity_ax2.set_title('Percent of students that are overweight or obese')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HncKYJ3S9YoX",
        "colab_type": "text"
      },
      "source": [
        "# Question 2: How do rates of high-BMI categories vary over time and by location?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vYfMlEzgd3P",
        "colab_type": "text"
      },
      "source": [
        "Now let's take a look at how the rates of high-BMI categories vary between states. Rather than considering the variation in high-BMI rates across states and populations simultaneously, we will consider variation by state only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEo9ISlQ9fqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_obesity = obesity[~(obesity.Location == 'US') & (obesity.Question.isin([\n",
        "    'Percent of students in grades 9-12 who have obesity',\n",
        "    'Percent of students in grades 9-12 who have an overweight classification']\n",
        "    ))]\n",
        "state_obesity = state_obesity[state_obesity.Group == 'Total']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QgPfzRpQOFiW"
      },
      "source": [
        "Let's split the columns by question and calculate the **overweight or obese** metric as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W8yjtKRzOE0T",
        "colab": {}
      },
      "source": [
        "state_obesity = state_obesity[['Year','Location','SampleSize','Question','Value']]\n",
        "state_obesity = state_obesity.pivot_table(index=['Year', 'Location', 'SampleSize'],\n",
        "                                    columns='Question', values = 'Value')\n",
        "del state_obesity.columns.name\n",
        "state_obesity.reset_index(inplace=True)\n",
        "state_obesity.rename(columns={\n",
        "    'Percent of students in grades 9-12 who have an overweight classification':'Overweight',\n",
        "    'Percent of students in grades 9-12 who have obesity':'Obese'}, inplace=True)\n",
        "state_obesity['OverweightOrObese'] = state_obesity.Overweight+state_obesity.Obese\n",
        "state_obesity.drop(columns=\"Overweight\", inplace=True)\n",
        "state_obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI8G_MLcQ1AQ",
        "colab_type": "text"
      },
      "source": [
        "Now let's try plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LokM7NyhGedy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_groups = state_obesity.groupby('Location')\n",
        "\n",
        "fig, ((state_ax1, state_ax2)) = plt.subplots(1, 2, figsize=(15,5))\n",
        "\n",
        "for name, group in state_groups:\n",
        "    state_ax1.plot(group.Year, group.Obese, linestyle='-')\n",
        "    state_ax1.scatter(group.Year, group.Obese, marker='o', linestyle='-',\n",
        "                      label=name)#s=group.SampleSize/250, \n",
        "    state_ax2.plot(group.Year, group.OverweightOrObese, linestyle='-')\n",
        "    state_ax2.scatter(group.Year, group.OverweightOrObese, marker='o', linestyle='-',\n",
        "                      label=name)#s=group.SampleSize/250, \n",
        "state_ax1.margins(0.1)\n",
        "state_ax1.set_xticks(state_obesity.Year.unique())\n",
        "state_ax1.set_ylim(0, 10*math.ceil(state_obesity.Obese.max()/10))\n",
        "state_ax1.legend(loc='upper left',ncol=5)\n",
        "state_ax1.set_title('Percent of students that are obese')\n",
        "state_ax2.margins(0.1)\n",
        "state_ax2.set_xticks(state_obesity.Year.unique())\n",
        "state_ax2.set_ylim(0, 10*math.ceil(state_obesity.OverweightOrObese.max()/10))\n",
        "state_ax2.legend(loc='upper left',ncol=5)\n",
        "state_ax2.set_title('Percent of students that are overweight or obese')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf-_hkOpJCNG",
        "colab_type": "text"
      },
      "source": [
        "Plotting all 51 locations (some territories are included, and some states are missing) is quite a mess. How can we make this easier to interpret? Let's look specifically at the locations with highest and lowest obesity rates.\n",
        "\n",
        "First, let's compare each location's rates to the national average for each specific year. That way, if a location only has data for certain years it will be taken into account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bwwmyaaULjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_obesity_diff_from_us = (state_obesity.groupby(['Location','Year']).mean(\n",
        "    )-us_obesity_total.groupby('Year').mean())[['Obese','OverweightOrObese']]\n",
        "state_obesity_diff_from_us.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rrwnzKNX8c6",
        "colab_type": "text"
      },
      "source": [
        "Now we can take the average across all years for which a state has data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx3JrjQmX8xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_mean_obesity = state_obesity_diff_from_us.reset_index().groupby(\n",
        "    'Location').mean()[['Obese','OverweightOrObese']]\n",
        "state_mean_obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPe4c7rXYxki",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can sort to get the locations with highest and lowest rates of high-BMI categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILJwQTAuYppR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lowest_obesity = list(state_mean_obesity.sort_values(by='Obese').index[0:5])\n",
        "lowest_obesity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAW6VEGjZObV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "highest_obesity = list(state_mean_obesity.sort_values(\n",
        "    by='Obese', ascending=False).index[0:5])\n",
        "highest_obesity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLxjjruNZOm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lowest_ovr_or_obesity = list(state_mean_obesity.sort_values(\n",
        "    by='OverweightOrObese').index[0:5])\n",
        "lowest_ovr_or_obesity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRqmUaycZOwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "highest_ovr_or_obesity = list(state_mean_obesity.sort_values(\n",
        "    by='OverweightOrObese', ascending=False).index[0:5])\n",
        "highest_ovr_or_obesity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26SJ0kj0SE87",
        "colab_type": "text"
      },
      "source": [
        "Now we should be able to plot trends over time with more clarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVc62cOKLEiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ((state_ax1, state_ax2)) = plt.subplots(1, 2, figsize=(15,5))\n",
        "\n",
        "state_ax1.plot(us_obesity_total.Year, us_obesity_total.Obese, 'k', label='US')\n",
        "for name, group in state_obesity[state_obesity.Location.isin(lowest_obesity)].groupby('Location'):\n",
        "    state_ax1.plot(group.Year, group.Obese, '-s', label=name)\n",
        "for name, group in state_obesity[state_obesity.Location.isin(highest_obesity) &\n",
        "                                 state_obesity.Location.isin(highest_ovr_or_obesity)].groupby('Location'):\n",
        "    state_ax1.plot(group.Year, group.Obese, '-o', label=name)\n",
        "for name, group in state_obesity[state_obesity.Location.isin(highest_obesity) &\n",
        "                                 ~state_obesity.Location.isin(highest_ovr_or_obesity)].groupby('Location'):\n",
        "    state_ax1.plot(group.Year, group.Obese, '--o', label=name)\n",
        "state_ax1.margins(0.1)\n",
        "state_ax1.set_xticks(state_obesity.Year.unique())\n",
        "state_ax1.set_ylim(0, 10*math.ceil(state_obesity.Obese.max()/10))\n",
        "state_ax1.legend(loc='upper left',ncol=3)\n",
        "state_ax1.set_title('Percent of students that are obese')\n",
        "\n",
        "state_ax2.plot(us_obesity_total.Year, us_obesity_total.OverweightOrObese, 'k', label='US')\n",
        "for name, group in state_obesity[state_obesity.Location.isin(lowest_ovr_or_obesity)].groupby('Location'):\n",
        "    state_ax2.plot(group.Year, group.OverweightOrObese, '-s', label=name)\n",
        "for name, group in state_obesity[state_obesity.Location.isin(highest_ovr_or_obesity) &\n",
        "                                 state_obesity.Location.isin(highest_obesity)].groupby('Location'):\n",
        "    state_ax2.plot(group.Year, group.OverweightOrObese, '-o', label=name)\n",
        "for name, group in state_obesity[state_obesity.Location.isin(highest_ovr_or_obesity) &\n",
        "                                 ~state_obesity.Location.isin(highest_obesity)].groupby('Location'):\n",
        "    state_ax2.plot(group.Year, group.OverweightOrObese, '--o', label=name)\n",
        "state_ax2.margins(0.1)\n",
        "state_ax2.set_xticks(state_obesity.Year.unique())\n",
        "state_ax2.set_ylim(0, 10*math.ceil(state_obesity.OverweightOrObese.max()/10))\n",
        "state_ax2.legend(loc='upper left',ncol=3)\n",
        "state_ax2.set_title('Percent of students that are overweight or obese')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W5wtoaMZXMS",
        "colab_type": "text"
      },
      "source": [
        "The five locations with below-average rates of high-BMI categories were Colorado, Idaho, Montana, Utah, and Wyoming, all located in the Rocky Mountains. The five with above-average rates were Guam, Kentucky, Mississippi, Tennessee, and either Arkansas (obesity) or Louisiana (overweightness or obesity). Besides Guam, these are all located along the Mississippi River. There was a fair amount of switching places between the locations in each group, but no switching between the groups. In fact, with the exception of 2013, none of these states ever crossed the U.S. average. It appears that geographic location may be strongly correlated with youth obesity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWCdp3RnWTn4",
        "colab_type": "text"
      },
      "source": [
        "# Question 3: What nutritional, behavioral, institutional, and environmental factors are associated with rates of high-BMI categories?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQYtMwSHsx7p",
        "colab_type": "text"
      },
      "source": [
        "Now we're ready to consider some of the other data from the survey responses. Let's separate the survey questions to get a better idea."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPwaePX8dera",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity = obesity.drop(columns='SampleSize').pivot_table(index=['Year', 'Location', 'Group'], columns='Question')\n",
        "obesity.columns = obesity.columns.get_level_values(1)\n",
        "del obesity.columns.name\n",
        "obesity.reset_index(inplace=True)\n",
        "obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zXuHP10eTD1",
        "colab_type": "text"
      },
      "source": [
        "Let's give these columns shorter names and create the **overweight or obese** column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njr8AVXMtC7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.rename(columns={'Percent of students in grades 9-12 watching 3 or more hours of television each school day':'TV',\n",
        "                        'Percent of students in grades 9-12 who achieve 1 hour or more of moderate-and/or vigorous-intensity physical activity daily':'Exercise',\n",
        "                        'Percent of students in grades 9-12 who consume fruit less than 1 time daily':'LackOfFruit',\n",
        "                        'Percent of students in grades 9-12 who consume vegetables less than 1 time daily':'LackOfVeggies',\n",
        "                        'Percent of students in grades 9-12 who drank regular soda/pop at least one time per day':'Soda',\n",
        "                        'Percent of students in grades 9-12 who have an overweight classification':'Overweight',\n",
        "                        'Percent of students in grades 9-12 who have obesity':'Obese',\n",
        "                        'Percent of students in grades 9-12 who participate in daily physical education':'PhysEd'}, inplace=True)\n",
        "obesity = obesity[['Year','Location','Group','TV','Exercise','PhysEd','LackOfFruit','LackOfVeggies','Soda','Overweight','Obese']]\n",
        "obesity['OverweightOrObese'] = obesity.Overweight+obesity.Obese\n",
        "obesity.drop(columns='Overweight', inplace=True)\n",
        "obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbZa2sygedkQ",
        "colab_type": "text"
      },
      "source": [
        "The columns pertaining to fruit and vegetable consumption have been named **LackOfFruit** and **LackOfVeggies** to indicate that higher data values correspond to less fruit or vegetable consumption, in contrast to the other columns.\n",
        "\n",
        "The factors included in this dataset can be described as nutritional (**LackOfFruit**, **LackOfVeggies**, **Soda**) and behavioral (**TV**, **Exercise**, **PhysEd**). The physical education factor is institutional in nature as well. By considering a [second dataset](https://data.cdc.gov/Nutrition-Physical-Activity-and-Obesity/Nutrition-Physical-Activity-and-Obesity-Policy-and/k8w5-7ju6) from the Division of Nutrition, Physical Activity, and Obesity, we can analyze the effects of state policy and infrastructure concerning nutrition and physical activity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x30v4QemqQ9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy = pd.read_csv('./Policy_and_Environmental_Data.csv')\n",
        "policy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yscQgea5tOMq",
        "colab_type": "text"
      },
      "source": [
        "This dataset looks similar to the obesity dataset in that it contains the answers to various questions across states and years. One difference is the lack of a column for population groups; the data are simply statewide statistics.\n",
        "\n",
        "Let's clean the dataset a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctROVpH-qQyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy = policy[['YearStart','LocationAbbr','Question','Data_Value']]\n",
        "policy.rename(columns={'YearStart':'Year','LocationAbbr':'Location','Data_Value':'Value'}, inplace=True)\n",
        "policy.sort_values(by=['Year','Location'], inplace=True)\n",
        "policy.reset_index(drop=True, inplace=True)\n",
        "policy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8sJFbrmuD87",
        "colab_type": "text"
      },
      "source": [
        "We can see that this dataset contains at least one year not present in the obesity dataset. Let's remove all the rows for which either the year or location don't match any of the obesity data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcX0aCxDrRdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy = policy[(policy.Location.isin(obesity.Location.unique())) &\n",
        "                (policy.Year.isin(obesity.Year.unique()))]\n",
        "policy.reset_index(drop=True, inplace=True)\n",
        "policy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UimmIusutQa",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the questions in this dataset to see which we want to consider."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Eyen5nrRpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy.Question.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIB7JNyGu6dN",
        "colab_type": "text"
      },
      "source": [
        "Some refer to breastfeeding, another aspect of health studied by the surveys. Others apply to children significantly younger than the high school students we are considering. Let's keep only the relevant questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsjnh72YrRy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy = policy[policy.Question.isin([\n",
        "    'Number of farmers markets per 100,000 residents',\n",
        "    'State child care regulations align with national standards for limiting total media time for children 2 years or older to not more than 30 minutes once a week',\n",
        "    'State child care regulations align with national standards for avoiding sugar, including concentrated sweets such as candy, sodas, sweetened drinks, fruit nectars, and flavored milk',\n",
        "    'State child care regulations align with national standards for serving fruits',\n",
        "    'State child care regulations align with national standards for serving vegetables',\n",
        "    'State has adopted some form of a Complete Streets policy',\n",
        "    'Percent of U.S. population living within 1/2 mile of a park',\n",
        "    'Percent of farmers markets that accept WIC Farmers Market Nutrition Program coupons',\n",
        "    'Number of food hubs in each state'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O21FLc1wBT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy.Value.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXRHZo6wwGf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy.Value.iloc[346]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65XYrkFHwdaq",
        "colab_type": "text"
      },
      "source": [
        "Here we are dealing with the same issue of numbers formatted as strings, but with some genuine string values that we must maintain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "779RZz9LvOyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy.Value = policy.Value.apply(lambda x: x if x in ['No','Yes'] else pd.to_numeric(x.replace(',','')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYuX4a2RwY8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy.Value.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_5pl_eEwqHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy.Value.iloc[346]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTw3wzHmxAfp",
        "colab_type": "text"
      },
      "source": [
        "Now we can split the questions into separate columns and rename."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwREj4bOv559",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy = policy.pivot_table(index=['Year', 'Location'], columns='Question', aggfunc='first')\n",
        "policy.columns = policy.columns.get_level_values(1)\n",
        "del policy.columns.name\n",
        "policy.reset_index(inplace=True)\n",
        "policy.rename(columns={'Number of farmers markets per 100,000 residents':'FarmMarket',\n",
        "                       'Number of food hubs in each state':'FoodHubs',\n",
        "                       'Percent of U.S. population living within 1/2 mile of a park':'NearPark',\n",
        "                       'Percent of farmers markets that accept WIC Farmers Market Nutrition Program coupons':'WIC',\n",
        "                       'State child care regulations align with national standards for avoiding sugar, including concentrated sweets such as candy, sodas, sweetened drinks, fruit nectars, and flavored milk':'SugarReg',\n",
        "                       'State child care regulations align with national standards for limiting total media time for children 2 years or older to not more than 30 minutes once a week':'MediaReg',\n",
        "                       'State child care regulations align with national standards for serving fruits':'FruitReg',\n",
        "                       'State child care regulations align with national standards for serving vegetables':'VeggieReg',\n",
        "                       'State has adopted some form of a Complete Streets policy':'CompleteStreets'}, inplace=True)\n",
        "policy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y70Vy0Fxiv-",
        "colab_type": "text"
      },
      "source": [
        "Clearly these columns have some missing values. But first let's merge this dataset with our obesity dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZMOweuYv5t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity = obesity.merge(policy, left_on=['Year','Location'],\n",
        "                        right_on=['Year','Location'], how='left')\n",
        "obesity = obesity[['Year','Location','Group','TV','Exercise','PhysEd',\n",
        "    'LackOfFruit','LackOfVeggies','Soda','FarmMarket','FoodHubs','NearPark',\n",
        "    'WIC','SugarReg','MediaReg','FruitReg','VeggieReg','CompleteStreets',\n",
        "    'Obese','OverweightOrObese']]\n",
        "obesity.replace('No', 0, inplace=True)\n",
        "obesity.replace('Yes', 1, inplace=True)\n",
        "obesity.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAzRXenMG022",
        "colab_type": "text"
      },
      "source": [
        "We should check if any columns have all the same values after the merge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHm14O_-Gnpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHEQccf1HAAU",
        "colab_type": "text"
      },
      "source": [
        "The **SugarReg** and **MediaReg** columns have standard deviations of zero after merging with the obesity dataset. We will have to drop them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFlrPonqHOTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obesity.drop(columns=['SugarReg','MediaReg'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUtRxLaJI9iR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK6WLtC8vlQ1",
        "colab_type": "text"
      },
      "source": [
        "Now let's take a look at the mean values of these factors within each location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkoZWd0Gqgfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_values_by_location = obesity[obesity.Group == 'Total'].drop(\n",
        "    columns=['Year','Group','Obese','OverweightOrObese']).groupby('Location').mean()\n",
        "mean_values_by_location.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDnHZzcJqjPh",
        "colab_type": "text"
      },
      "source": [
        "The list of locations lowest in obesity and the list of locations lowest in overweightness or obesity are identical, so we can use either one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2pgyYKUJpGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lowest_BMI = lowest_obesity.copy()\n",
        "lowest_BMI_mean_values = mean_values_by_location.loc[lowest_BMI].mean()\n",
        "lowest_BMI_mean_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdnOXJrFKIvY",
        "colab_type": "text"
      },
      "source": [
        "For the locations with the highest BMI categories, we must combine the two lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbindqqMJo5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "highest_BMI = highest_obesity.copy()\n",
        "highest_BMI.extend(highest_ovr_or_obesity)\n",
        "highest_BMI = list(np.unique(highest_BMI))\n",
        "highest_BMI_mean_values = mean_values_by_location.loc[highest_BMI].mean()\n",
        "highest_BMI_mean_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNyDGdr2KUkb",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the U.S. average values as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGQLi22EJiMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_avg_values = mean_values_by_location.loc['US']\n",
        "us_avg_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXf_geL_Kden",
        "colab_type": "text"
      },
      "source": [
        "The **FoodHubs**, **FruitReg**, **VeggieReg**, and **CompleteStreets** factors represent amounts rather than percentages, so the data labeled 'US' is giving us a sum rather than an average. We can replace these incorrect numbers with averages taken across all states. The reason we did not just do this originally for all factors is that for those factors representing percentages, we do not want the simple average of the location data. We instead want the national average, which would be equal to the average of the location data weighted by location population per year. Calculating it this way would be far too tedious when we can simply use the data labeled 'US'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdTCcRJsLFi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "us_avg_values.loc[['FoodHubs','FruitReg','VeggieReg',\n",
        "    'CompleteStreets']] = mean_values_by_location.mean().loc[['FoodHubs',\n",
        "    'FruitReg','VeggieReg','CompleteStreets']]\n",
        "us_avg_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlhzmstSusTa",
        "colab_type": "text"
      },
      "source": [
        "Now we can plot how each factor differs between the lowest BMI locations, U.S. average, and the highest BMI locations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8hQbueOsqN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = mean_values_by_location.columns\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18,4))\n",
        "rects1 = ax.bar(x-width, lowest_BMI_mean_values, width, color = '#3377EE',\n",
        "                label='Average for low-BMI locations')\n",
        "rects2 = ax.bar(x, us_avg_values, width, color = '#FFDD00',\n",
        "                label='U.S. average')\n",
        "rects3 = ax.bar(x+width, highest_BMI_mean_values, width, color = '#FF4433',\n",
        "                label='Average for high-BMI locations')\n",
        "\n",
        "ax.set_ylabel(' ')\n",
        "ax.set_title('Metrics for high- and low-BMI locations vs. U.S. average')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs2UMHkJPKUy",
        "colab_type": "text"
      },
      "source": [
        "In order to better visualize all factors, we can normalize the data within each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79fmLJHtOJlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_values = pd.concat([lowest_BMI_mean_values, us_avg_values, highest_BMI_mean_values], axis=1)\n",
        "mean_values.columns = ['LowBMI', 'avg', 'HighBMI']\n",
        "lowest_BMI_normalized = mean_values.LowBMI/mean_values.max(axis=1)\n",
        "avg_BMI_normalized = mean_values.avg/mean_values.max(axis=1)\n",
        "highest_BMI_normalized = mean_values.HighBMI/mean_values.max(axis=1)\n",
        "\n",
        "labels = mean_values_by_location.columns\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18,4))\n",
        "rects1 = ax.bar(x-width, lowest_BMI_normalized, width, color = '#3377EE',\n",
        "                label='Average for low-BMI locations')\n",
        "rects2 = ax.bar(x, avg_BMI_normalized, width, color = '#FFDD00',\n",
        "                label='U.S. average')\n",
        "rects3 = ax.bar(x+width, highest_BMI_normalized, width, color = '#FF4433',\n",
        "                label='Average for high-BMI locations')\n",
        "\n",
        "ax.set_ylabel(' ')\n",
        "ax.set_title('Metrics for high- and low-BMI locations vs. U.S. average')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylim(top=1.4)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PnLw70kWq9k",
        "colab_type": "text"
      },
      "source": [
        "Low-BMI locations have percentages lower than the national average of high-school students that \"watch 3 or more hours of television each school day\", \"consume vegetables less than 1 time daily\", and \"drink regular soda/pop at least one time per day\". Meanwhile, high-BMI locations have percentages higher than the national average for these same categories, as well as for students \"consuming fruit less than 1 time daily\".\n",
        "\n",
        "Low-BMI locations also have more farmers markets per capita and more people living within half a mile of a park than the national average, while high-BMI locations have fewer of these than the national average. Interestingly, none of the low-BMI locations during any of the years in this data have \"state child care regulations that align with national standards for serving fruits\" or likewise for vegetables. High-BMI locations have these regulations for serving vegetables at rates higher than average, but not for fruits. Perhaps the high-BMI locations have attempted to address their rates of high-BMI categories among students through regulations, while the low-BMI locations have not seen the need.\n",
        "\n",
        "Comparing these factors among three groups of locations is not the only way to consider their correlation with the prevalence of high-BMI categories. We can calculate the Pearson correlation coefficient between all columns in our data., and visualize the correlations between the high-BMI metrics and associated factors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW6TRi50My5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, figsize=(8,7))\n",
        "\n",
        "ax1.set_title('Correlation across location')\n",
        "df = obesity[~(obesity.Location == 'US') & (obesity.Group == 'Total')]\n",
        "heatmap(df.corr().drop(columns=['Year','Obese','OverweightOrObese']\n",
        "    ).loc[['Obese','OverweightOrObese']], vmin=-1, vmax=1, annot=True, fmt=\".2f\",\n",
        "    cmap='RdBu_r', cbar=False, ax=ax1)\n",
        "\n",
        "ax2.set_title('Correlation across location and school grade')\n",
        "df = obesity[~(obesity.Location == 'US') & (obesity.Group.isin(grade_grouping))]\n",
        "heatmap(df.corr().drop(columns=['Year','Obese','OverweightOrObese']\n",
        "    ).loc[['Obese','OverweightOrObese']], vmin=-1, vmax=1, annot=True, fmt=\".2f\",\n",
        "    cmap='RdBu_r', cbar=False, ax=ax2)\n",
        "\n",
        "ax3.set_title('Correlation across location and gender')\n",
        "df = obesity[~(obesity.Location == 'US') & (obesity.Group.isin(gender_grouping))]\n",
        "heatmap(df.corr().drop(columns=['Year','Obese','OverweightOrObese']\n",
        "    ).loc[['Obese','OverweightOrObese']], vmin=-1, vmax=1, annot=True, fmt=\".2f\",\n",
        "    cmap='RdBu_r', cbar=False, ax=ax3)\n",
        "\n",
        "ax4.set_title('Correlation across location and race/ethnicity')\n",
        "df = obesity[~(obesity.Location == 'US') & (obesity.Group.isin(race_ethnicity_grouping))]\n",
        "heatmap(df.corr().drop(columns=['Year','Obese','OverweightOrObese']\n",
        "    ).loc[['Obese','OverweightOrObese']], vmin=-1, vmax=1, annot=True, fmt=\".2f\",\n",
        "    cmap='RdBu_r', cbar=False, ax=ax4)\n",
        "\n",
        "plt.setp(ax1.get_yticklabels(), rotation=0)\n",
        "plt.setp(ax2.get_yticklabels(), rotation=0)\n",
        "plt.setp(ax3.get_yticklabels(), rotation=0)\n",
        "plt.setp(ax4.get_yticklabels(), rotation=0)\n",
        "plt.tight_layout(1.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S_2rkI-UoV-",
        "colab_type": "text"
      },
      "source": [
        "The relative importance of factors mostly matches what we saw in the bar chart. Watching TV, drinking soda, eating fruits less often, and especially eating vegetables less often are positively correlated with higher rates of high-BMI across the statewide data, grade-grouped data, gender-grouped data, and race/ethnicity-grouped data. Living near a park is negatively correlated with higher rates of high-BMI across these data groups. However, the numbers of farmers markets per capita and the prevalence of vegetable regulations do not appear significant from this analysis, in contrast to the bar chart.\n",
        "\n",
        "Also, it is important to remember that for the policy/environmental factors, we do not have population-specific data. In the correlation across location and race/ethnicity for example, we are looking at the correlation between obesity rates in different racial/ethnic groups across many locations versus the percent of all students in that location, regardless of racial/ethnic group, living within half a mile of a park. With more detailed data we would be able to further refine this analysis and consider more specific questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv_DufB1hV9Y",
        "colab_type": "text"
      },
      "source": [
        "# Question 4: Can we predict rates of high-BMI categories?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2BSOqHxIGrl",
        "colab_type": "text"
      },
      "source": [
        "The correlation calculation we performed quantifies the degree to which there is a linear relationship between one of our high-BMI metrics of interest and another factor in the data. However, it does not take into account the other factors. To do that we can train a linear regression model on the data and see what factors are most important for model performance.\n",
        "\n",
        "Let's start with the data across all locations and drop the columns we don't want to be in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyXnOtUNKZI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = obesity[~(obesity.Location == 'US') & (obesity.Group == 'Total')]\n",
        "df.drop(columns=['Year','Location','Group','OverweightOrObese'], inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcoLED4xLEJG",
        "colab_type": "text"
      },
      "source": [
        "There are a lot of missing values which we must handle before building a model. A common strategy is to impute (fill) the missing values with the a single value based on the statistics of that column. Let's do this with the mode (the cmost frequent value)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXWRNg25LCd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp = impute.SimpleImputer(strategy='most_frequent')\n",
        "df[df.columns] = imp.fit_transform(df[df.columns])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtPT5Ao_Loko",
        "colab_type": "text"
      },
      "source": [
        "Now we will split the data into a training set and a test set, build a linear regression model, train it, and use it to make predictions of obesity rates based on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5heTEf0ULnmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop('Obese', axis=1)\n",
        "y = df['Obese']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_train_preds = model.predict(X_train)\n",
        "y_test_preds = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx5CKDOVVnCS",
        "colab_type": "text"
      },
      "source": [
        "We can use the describe function from SciPy to look at the minimum and maximum of the training set and test set predictions. The percent of students that are obese can never be less than 0 or greater than 100. If any predictions fall outside these boundaries, or even if they are close, then linear regression could be a bad choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpdd3VVGUOks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats.describe(y_train_preds)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTLb87zRUO1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats.describe(y_test_preds)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Liw4mFU6WNDp",
        "colab_type": "text"
      },
      "source": [
        "Not only are these percentages possible, they seem reasonable based on what we know about the data. Now we can quantify the accuracy of our model using the coefficient of determination between our predictions and the correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42KJYj6rMlQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2_score(y_train, y_train_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8V9l71cMnyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2_score(y_test, y_test_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfI0eCUsMQlP",
        "colab_type": "text"
      },
      "source": [
        "Model accuracy is only 53.5% for the training set. So even when considering all factors at once and being given all the right answers, a linear model can only achieve so much. The data is far from perfectly correlated.\n",
        "\n",
        "The model accuracy for the test set is 48.4%, not far behind the training score. The model is generalizing fairly well to new samples, despite both scores being lower than we might like.\n",
        "\n",
        "Now let's look at which factors the model weights most heavily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlKjcPfuI1wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(index=X.columns, data=model.coef_, columns = ['coef']\n",
        "             ).sort_values(by='coef', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBaiHL5iO6gB",
        "colab_type": "text"
      },
      "source": [
        "Negative values indicate that the model predicts lower obesity when the factor value is high, while for positive coefficients it predicts higher rates. The absolute value of the coefficient represents the degree of influence of that factor on model predictions. Currently **VeggieReg** and **CompleteStreets** are being considered most heavily by the model. From the bar chart we saw that these factors, especially **VeggieReg**, seem to be correlated with geographic lcoation.\n",
        "\n",
        "Will model performance improve if we consider geographic location? Rather than training the model on the specific state or territory, let's take a broader approach. We can use the four regions of the country defined by the [U.S. Census Bureau](https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf): Northeast, Midwest, South, and West. Territories are not classified in a region, so we will group them in a separate class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnkEegU2Sf53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "west = ['AK', 'HI', 'WA', 'OR', 'CA', 'NV', 'ID', 'MT', 'WY', 'UT', 'CO', 'AZ', 'NM']\n",
        "midwest = ['ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'IL', 'IN', 'MI', 'OH']\n",
        "south = ['TX', 'OK', 'AR', 'LA', 'KY', 'TN', 'MS', 'AL', 'WV', 'MD', 'DE', 'DC', 'VA', 'NC', 'SC', 'GA', 'FL']\n",
        "northeast = ['PA', 'NJ', 'NY', 'CT', 'RI', 'MA', 'VT', 'NH', 'ME']\n",
        "territories = ['VI', 'GU', 'PR']\n",
        "\n",
        "obesity_with_region = obesity.copy()\n",
        "obesity_with_region['Region'] = obesity_with_region.Location.apply(\n",
        "    lambda x: 'West' if x in west else 'Midwest' if x in midwest else 'South'\n",
        "    if x in south else 'Northeast' if x in northeast else 'Territories'\n",
        "    if x in territories else 'Other')\n",
        "obesity_with_region.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-1KAtpbS6RT",
        "colab_type": "text"
      },
      "source": [
        "We'll process the data as before, but with an additional step: encoding our new categorical variable numerically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UagKkbRNS6zD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = obesity_with_region[~(obesity_with_region.Location == 'US') &\n",
        "                         (obesity_with_region.Group == 'Total')]\n",
        "df.drop(columns=['Year','Location','Group','OverweightOrObese'], inplace=True)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCw7vhOyTmh6",
        "colab_type": "text"
      },
      "source": [
        "Now we have four columns of zeros and ones to tell us whether or not a location is in the Northeast, South, territories, or West. Zeros in all four columns mean that it is in the Midwest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0DJz8O8TJ-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp = impute.SimpleImputer(strategy='most_frequent')\n",
        "df[df.columns] = imp.fit_transform(df[df.columns])\n",
        "X = df.drop('Obese', axis=1)\n",
        "y = df['Obese']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_train_preds = model.predict(X_train)\n",
        "y_test_preds = model.predict(X_test)\n",
        "r2_score(y_train, y_train_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48NS7kx5UeCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2_score(y_test, y_test_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuIrLbkGUlSD",
        "colab_type": "text"
      },
      "source": [
        "By simply telling the model to which of these five regions each sample belongs, model accuracy has improved. Let's zoom in on the location a bit more by providing the region subdivisions used by the Census Bureau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pADPfD7PVor_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NewEngland = ['CT', 'ME', 'MA', 'NH', 'RI', 'VT']\n",
        "MidAtlantic = ['NJ', 'NY', 'PA']\n",
        "EastNorthCentral = ['IL', 'IN', 'MI', 'OH', 'WI']\n",
        "WestNorthCentral = ['IA', 'KS', 'MN', 'MO', 'NE', 'ND', 'SD']\n",
        "SouthAtlantic = ['DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV']\n",
        "EastSouthCentral = ['AL', 'KY', 'MS', 'TN']\n",
        "WestSouthCentral = ['AR', 'LA', 'OK', 'TX']\n",
        "Mountain = ['AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY']\n",
        "Pacific = ['AK', 'CA', 'HI', 'OR', 'WA']\n",
        "\n",
        "obesity_with_division = obesity.copy()\n",
        "obesity_with_division['Division'] = obesity_with_division.Location.apply(\n",
        "    lambda x: 'NewEngland' if x in NewEngland else 'MidAtlantic'\n",
        "    if x in MidAtlantic else 'EastNorthCentral' if x in EastNorthCentral else\n",
        "    'WestNorthCentral' if x in WestNorthCentral else 'SouthAtlantic'\n",
        "    if x in SouthAtlantic else 'EastSouthCentral' if x in EastSouthCentral else\n",
        "    'WestSouthCentral' if x in WestSouthCentral else 'Mountain'\n",
        "    if x in Mountain else 'Pacific' if x in Pacific else 'Territories'\n",
        "    if x in territories else 'Other')\n",
        "\n",
        "df = obesity_with_division[~(obesity_with_division.Location == 'US') &\n",
        "                         (obesity_with_division.Group == 'Total')]\n",
        "df.drop(columns=['Year','Location','Group','OverweightOrObese'], inplace=True)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "imp = impute.SimpleImputer(strategy='most_frequent')\n",
        "df[df.columns] = imp.fit_transform(df[df.columns])\n",
        "X = df.drop('Obese', axis=1)\n",
        "y = df['Obese']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_train_preds = model.predict(X_train)\n",
        "y_test_preds = model.predict(X_test)\n",
        "r2_score(y_train, y_train_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV-dxaS6V1WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2_score(y_test, y_test_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qz2u9lBV4Cg",
        "colab_type": "text"
      },
      "source": [
        "We've managed to get test accuracy above 60%; still not ideal for a useful predictive model. Let's consider some other algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpyBgdPXzPlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_obesity_model(df, response_col, cols_to_drop, test_size, model_type):\n",
        "    '''\n",
        "    INPUT:\n",
        "    df - pandas dataframe with obesity data or a subset thereof\n",
        "    response_col - column of data to predict\n",
        "    cols_to_drop - columns to drop and not train on\n",
        "    test_size - proportion of the test-train split that is for testing, between 0 and 1\n",
        "    model_type - choice of sklearn algorithm: 'LinearRegression', 'Lasso', 'Ridge',\n",
        "        'ElasticNet', 'SVR', 'Bagging', 'RandomForest', 'AdaBoost'\n",
        "    impute_strategy - how to impute missing values: 'mean', 'median', 'most_frequent'\n",
        "    scaling - Boolean, apply min-max scaling if True or no scaling if False\n",
        "\n",
        "    STEPS:\n",
        "    Drop the rows with missing values for the response column\n",
        "    Drop columns with all NaN values\n",
        "    Drop the columns on which we do not want to train, such as the location or the other response column\n",
        "    Split categorical variables using get_dummies()\n",
        "    Impute missing values with the mean\n",
        "    Split into explanatory and response variables\n",
        "    Split into training and test sets\n",
        "    Predict the response variable\n",
        "    Score the model\n",
        "\n",
        "    OUTPUT:\n",
        "    a pandas Series that contains the training score and test score\n",
        "    '''\n",
        "    \n",
        "    # Drop the rows with missing response values\n",
        "    df = df.dropna(subset=[response_col], axis=0)\n",
        "\n",
        "    # Drop columns with all NaN values\n",
        "    df = df.dropna(how='all', axis=1)\n",
        "\n",
        "    # Drop the columns on which we do not want to train, including the other response column\n",
        "    df.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "    # Get dummies\n",
        "    df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "    # Impute missing values\n",
        "    imp = impute.SimpleImputer(strategy='most_frequent')\n",
        "    df[df.columns] = imp.fit_transform(df[df.columns])\n",
        "\n",
        "    # Split into explanatory and response variables\n",
        "    X = df.drop(response_col, axis=1)\n",
        "    y = df[response_col]\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Build model\n",
        "    if model_type == 'LinearRegression':\n",
        "      model = linear_model.LinearRegression()\n",
        "    elif model_type == 'Lasso':\n",
        "      model = linear_model.Lasso()\n",
        "    elif model_type == 'Ridge':\n",
        "      model = linear_model.Ridge()\n",
        "    elif model_type == 'ElasticNet':\n",
        "      model = linear_model.ElasticNet()\n",
        "    elif model_type == 'SVR':\n",
        "      model = svm.SVR(kernel='rbf', C=40)\n",
        "\n",
        "    # Fit model to training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict for training and test data\n",
        "    y_train_preds = model.predict(X_train)\n",
        "    y_test_preds = model.predict(X_test)\n",
        "\n",
        "    # Score model on training and test data\n",
        "    training_score = r2_score(y_train, y_train_preds)\n",
        "    test_score = r2_score(y_test, y_test_preds)\n",
        "\n",
        "    # Return scores\n",
        "    score = pd.Series({'training_score':training_score, 'test_score':test_score})\n",
        "\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ_huNTZXD0y",
        "colab_type": "text"
      },
      "source": [
        "This function perfoms the steps of data preparation, model building, training, predicition, and scoring for five different choices of algorithm: linear regression, lasso regression, ridge regression, elastic net regression, and support vector regression (SVR). Lasso and ridge are regularization techniques that perform linear regression but with penalties imposed on coefficients being too high. They use two different penalty functions. Elastic net combines these two regularization methods in an attempt to overcome their limitations. SVR is an extension of support vector machines, originally used in classification problems. Let's build another function to plot model accuracy on various subsets of the data using these five algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh74EeM3FUU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_alg_performance(df, response_col):\n",
        "    scores = pd.DataFrame({'LinearRegression':[0]*4, 'Lasso':[0]*4,\n",
        "        'Ridge':[0]*4, 'ElasticNet':[0]*4, 'SVR':[0]*4}, index=[\n",
        "        '[\"Total\"]', 'grade_grouping', 'gender_grouping',\n",
        "        'race_ethnicity_grouping'])\n",
        "\n",
        "    other_col = [x for x in ['Obese','OverweightOrObese'] if not x == response_col][0]\n",
        "    cols_to_drop = ['Year','Location','Group']\n",
        "    cols_to_drop.append(other_col)\n",
        "\n",
        "    for grouping in scores.index:\n",
        "      df_grouping = eval('df[~(df.Location == \"US\") & (df.Group.isin('+grouping+'))]')\n",
        "      for model_type in scores.columns:\n",
        "        score = train_obesity_model(df_grouping, response_col, cols_to_drop,\n",
        "            test_size=.3, model_type = model_type)\n",
        "        scores.loc[grouping, model_type] = score.test_score\n",
        "\n",
        "    labels = ['Data across location', 'Data across location and school grade',\n",
        "        'Data across location and gender', 'Data across location and race/ethnicity']\n",
        "\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.15\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(18,4))\n",
        "    rects1 = ax.bar(x-2*width, scores['LinearRegression'], width, color = '#3377EE',\n",
        "                    label='Linear regression')\n",
        "    rects2 = ax.bar(x-width, scores['Lasso'], width, color = '#FFDD00',\n",
        "                    label='Lasso regression')\n",
        "    rects3 = ax.bar(x, scores['Ridge'], width, color = '#FF4433',\n",
        "                    label='Ridge regression')\n",
        "    rects4 = ax.bar(x+width, scores['ElasticNet'], width, color = '#55DD55',\n",
        "                    label='ElasticNet')\n",
        "    rects5 = ax.bar(x+2*width, scores['SVR'], width, color = '#AA55BB',\n",
        "                    label='SVR')\n",
        "\n",
        "    ax.set_ylabel(' ')\n",
        "    if response_col == 'Obese':\n",
        "      ax.set_title('Test score for predicting the percent of students obese')\n",
        "    elif response_col == 'OverweightOrObese':\n",
        "      ax.set_title('Test score for predicting the percent of students overweight or obese')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.set_ylim((0,1.2))\n",
        "    ax.legend()\n",
        "    ax.annotate('Max test score: '+str(round(scores.max().max(), 2)),\n",
        "                (1.25, 1.05*scores.max().max()))\n",
        "    ax.axhline(y=scores.max().max(), xmin=0, xmax=6, linestyle='--', c='r')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIGSTijRMzSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_alg_performance(obesity, 'Obese')\n",
        "plot_alg_performance(obesity, 'OverweightOrObese')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRHC3OswaGx4",
        "colab_type": "text"
      },
      "source": [
        "For both the percent of students obese and those overweight or obese, support vector regression outperforms the other algorithms. We can also see that predictive performance is better across all algorithms for the overall data by location. This may be because there are simply more data samples, which allow for more training, more learning, and thus higher accuracy when generalizing to the test samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TMJdkstzlAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_alg_performance(obesity_with_region, 'Obese')\n",
        "plot_alg_performance(obesity_with_region, 'OverweightOrObese')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imdvrdb0cFpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_alg_performance(obesity_with_division, 'Obese')\n",
        "plot_alg_performance(obesity_with_division, 'OverweightOrObese')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "211G70hxb4sL",
        "colab_type": "text"
      },
      "source": [
        "The dominance of SVR is less when region or division are included; ridge regression and plain linear regression also perform well. Generally in data science the quality of the data is more important than the choice of algorithm. In order to have more faith in the questions we can answer from this dataset, we might want more data samples, or more features on which to train.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BEwK1rkdm0m",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR5oy38Qdu-r",
        "colab_type": "text"
      },
      "source": [
        "In examining this data we have seen that the percents of high-school students in the United States that are obese and those that are overweight or obese have increased from 2001 to 2017, are higher in certain racial/ethnic groups, and are higher in males than females, although females are catching up. We have also learned that five states in the Rocky Mountains have the lowest rates of these high-BMI categories, and in those states students tend to watch less TV, eat more vegetables, and drink less soda than the national average. Those states also have more farmers markets per capita and more people living within half a mile of a park than the national average. Five states along the Mississippi River and Guam have the highest rates of these high-BMI categories, and students in those locations tend to watch more TV, eat fewer fruits and vegetables, and drink more soda than the national average. Those locations also have fewer farmers markets per capita and fewer people living within half a mile of a park than the national average. Similar results are seen in the single-factor correlation coefficients. We have also shown that by providing some level of information on geographic location, the test set accuracy of a linear model can be improved.\n",
        "\n",
        "One important caveat is that BMI is not the same as body fat percentage, nor is it perfectly correlated. The metric has been criticized for its bias across height ranges (being underpredicted for shorter individuals and overpredicted for taller) and failure to account for body composition properties, such as a person's degree of musculature.\n",
        "\n",
        "Another is that much of the data considered here are from self-report surveys, including a student's height and weight, which are used to calculate BMI. The [YRBSS methodology documentation](https://www.cdc.gov/mmwr/pdf/rr/rr6201.pdf) mentions a CDC study on the reliability of these two question in particular, in which students' heights and weights were measured after having taken the questionnaire: \"Self-reported height, weight, and BMI calculated from these values were substantially reliable, but on average, students in the study overreported their height by 2.7 inches and underreported their weight by 3.5 pounds, which indicates that YRBSS probably underestimates the prevalence of overweight and obesity in adolescent populations.\" In addition, the policy data comes from aggregating various state and local level reports under a common standard, for example that the \"state has adopted some form of a Complete Streets policy\".\n",
        "\n",
        "Finally, the factors considered here are far from the only ones that could be used to understand and predict rates of youth obesity. The documentation states that the \"CDC decided that the system should focus almost exclusively on health-risk behaviors rather than on the determinants of these behaviors (e.g., knowledge, attitudes, beliefs, and skills), because there is a more direct connection between specific health-risk behaviors and specific health outcomes than between determinants of behaviors and health outcomes.\" However, research and analysis of the determining factors of risk behaviors is undoubtedly important in the effort to address this issue."
      ]
    }
  ]
}